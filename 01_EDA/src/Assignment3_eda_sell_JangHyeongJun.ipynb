{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17845/1883619435.py:17: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support.select import Select\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "from glob import glob\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen, Request\n",
    "from user_agent import generate_user_agent\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import koreanize_matplotlib\n",
    "import json\n",
    "import folium\n",
    "import warnings\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_main = \"https://www.applyhome.co.kr/ai/aia/selectAPTLttotPblancListView.do\"\n",
    "\n",
    "# Chrome 드라이버 초기화\n",
    "driver = webdriver.Chrome(service=Service(\"../driver/chromedriver\"))\n",
    "driver.get(url_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selenium을 사용하여 현재 페이지의 소스 가져오기\n",
    "present_url = driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BeautifulSoup을 사용하여 HTML 파싱\n",
    "soup = BeautifulSoup(present_url, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 철근 누락 적발 시공사 명단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://realty.chosun.com/site/data/html_dir/2023/07/31/2023073101968.html, 국토교통부 재인용 기사\n",
    "bad_company = [\"대보건설\", \"대림(DL)건설\", \"삼환기업\", \"이수건설\", \"한신건설\", \"양우종합건설\", \"효성중공업\", \"대우산업개발\", \"에이스건설\", \"한신공영\", \"태평양개발\", \"동문건설\", \"남영건설\", \"한라\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 청약 시공사 리스트 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 담을 리스트 초기화\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr 요소들을 찾아 반복\n",
    "for tr in soup.find_all('tr'):\n",
    "    # 각 컬럼의 값을 가져와서 딕셔너리로 저장\n",
    "    td_element = tr.find('td')\n",
    "    b_element = tr.find('b')\n",
    "    word_cut_element = tr.find(class_='word_cut')\n",
    "\n",
    "    # 요소가 존재하는지 확인하고 데이터에 추가\n",
    "    if td_element and b_element and word_cut_element:\n",
    "        region = td_element.text.strip()\n",
    "        housing_name = b_element.text.strip()\n",
    "        construction_company = word_cut_element.text.strip()\n",
    "\n",
    "        # 딕셔너리에 저장\n",
    "        row = {'지역': region, '주택명': housing_name, '시공사': construction_company}\n",
    "        data.append(row)\n",
    "\n",
    "# 중복된 데이터 제거\n",
    "data = [dict(t) for t in {tuple(d.items()) for d in data}]\n",
    "\n",
    "# 데이터 프레임 생성\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 결과 출력\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 페이지 이동 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 담을 리스트 초기화\n",
    "data = []\n",
    "\n",
    "# 다음 페이지 버튼을 클릭하여 더 많은 데이터를 로드하고 파싱합니다.\n",
    "while True:\n",
    "    # 현재 페이지의 HTML 가져오기\n",
    "    present_url = driver.page_source\n",
    "    \n",
    "    # BeautifulSoup을 사용하여 HTML 파싱\n",
    "    soup = BeautifulSoup(present_url, 'html.parser')\n",
    "    \n",
    "    # tr 요소들을 찾아 반복\n",
    "    for tr in soup.find_all('tr'):\n",
    "        try:\n",
    "            # 각 컬럼의 값을 가져와서 딕셔너리로 저장\n",
    "            td_element = tr.find('td')\n",
    "            b_element = tr.find('b')\n",
    "            word_cut_element = tr.find(class_='word_cut')\n",
    "\n",
    "            # 요소가 존재하는지 확인하고 데이터에 추가\n",
    "            if td_element and b_element and word_cut_element:\n",
    "                region = td_element.text.strip()\n",
    "                housing_name = b_element.text.strip()\n",
    "                construction_company = word_cut_element.text.strip()\n",
    "\n",
    "                # 딕셔너리에 저장\n",
    "                row = {'지역': region, '주택명': housing_name, '시공사': construction_company}\n",
    "                data.append(row)\n",
    "        except AttributeError as e:\n",
    "            print(\"Error:\", e)\n",
    "            continue\n",
    "    \n",
    "    # 현재 페이지 번호 가져오기\n",
    "    current_page_element = soup.find('a', class_='active')\n",
    "    current_page = int(current_page_element.text.strip())\n",
    "\n",
    "    # 다음 페이지로 이동\n",
    "    next_page = current_page + 1\n",
    "    try:\n",
    "        next_page_button = driver.find_element(By.XPATH, f'//a[@href=\"?pageIndex={next_page}\"]')\n",
    "        next_page_button.click()\n",
    "        time.sleep(2)  # 페이지가 로드될 때까지 잠시 대기\n",
    "    except NoSuchElementException:\n",
    "        break\n",
    "    \n",
    "# 데이터 프레임 생성\n",
    "df_APT_list = pd.DataFrame(data)\n",
    "next_page = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     지역                   주택명         시공사\n",
      "0    경기     남양주별내Ａ１－２　행복주택　추가     대보건설(주)\n",
      "1    경기       이천마장　Ａ３　행복주택　추가  한국토지주택공사서울\n",
      "2    경기      안성공도　참아름　국민임대　예비     주공 안성공도\n",
      "3    광주  광주효천２　Ａ３　１０년　분납임대　예비  한국토지주택광주전남\n",
      "4    광주  광주효천２　Ａ１　１０년　공공임대　예비  한국토지주택광주전남\n",
      "..   ..                   ...         ...\n",
      "109  경기  위례신도시　Ａ３－４ｂＢＬ　우미린　１차     (주)우미개발\n",
      "110  부산      힐스테이트　명륜　２차　（부산）  현대엔지니어링(주)\n",
      "111  강원          태백소도　국민임대　예비  한국토지주택공사강원\n",
      "112  강원         동해천곡６　국민임대　예비  한국토지주택공사강원\n",
      "113  전북         디오션시티　더샵　（군산）    (주)포스코건설\n",
      "\n",
      "[114 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(df_APT_list)\n",
    "df_APT_list.to_excel(\"../data/APT_list.xlsx\", engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"시공사\" 컬럼의 텍스트가 없는 행 제외\n",
    "df_APT_list = df_APT_list[df_APT_list['시공사'].notna()]\n",
    "\n",
    "# bad_company를 데이터프레임으로 변환\n",
    "bad_companys = pd.DataFrame({'bad_company': bad_company})\n",
    "\n",
    "# \"시공사\" 컬럼의 요소와 텍스트가 같거나 서로 포함되는 문자열 관계인 경우 찾기\n",
    "bad_company_elements = []\n",
    "for index, row in df_APT_list.iterrows():\n",
    "    for company in bad_company:\n",
    "        if company in row['시공사'] or row['시공사'] in company:\n",
    "            bad_company_elements.append(row)\n",
    "            break\n",
    "\n",
    "# bad_company_elements를 데이터프레임으로 변환\n",
    "bad_companys = pd.DataFrame(bad_company_elements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     지역                   주택명      시공사\n",
      "0    경기     남양주별내Ａ１－２　행복주택　추가  대보건설(주)\n",
      "6    충남   논산내동２－１　１０년　공공임대　예비  한신공영(주)\n",
      "34   세종     세종　더휴　예미지　Ｌ２　（민영）  한신공영(주)\n",
      "35   세종     세종　더휴　예미지　Ｌ２　（국민）  한신공영(주)\n",
      "36   세종     세종　더휴　예미지　Ｌ１　（민영）  한신공영(주)\n",
      "37   세종     세종　더휴　예미지　Ｌ１　（국민）  한신공영(주)\n",
      "106  경기  김포한강Ａｃ－０５　１０년　공공임대예비         \n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(bad_companys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테그 사이에 정보가 없으면 -> None! space (\" \")와는 다름!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"시공사\" 컬럼의 요소와 텍스트가 같거나 서로 포함되는 문자열 관계인 경우 찾기\n",
    "bad_company_elements = []\n",
    "for index, row in df_APT_list.iterrows():\n",
    "    for company in bad_company:\n",
    "        # row['시공사'] 또는 company가 None이 아니고, 서로 포함되는 문자열 관계인 경우\n",
    "        if row['시공사'] and company and (company in row['시공사'] or row['시공사'] in company):\n",
    "            bad_company_elements.append(row)\n",
    "            break\n",
    "\n",
    "# None을 제외한 bad_company_elements를 데이터프레임으로 변환\n",
    "bad_companys = pd.DataFrame([elem for elem in bad_company_elements if elem is not None])\n",
    "\n",
    "# bad_company_elements를 데이터프레임으로 변환\n",
    "bad_companys = pd.DataFrame(bad_company_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    지역                  주택명      시공사\n",
      "0   경기    남양주별내Ａ１－２　행복주택　추가  대보건설(주)\n",
      "6   충남  논산내동２－１　１０년　공공임대　예비  한신공영(주)\n",
      "34  세종    세종　더휴　예미지　Ｌ２　（민영）  한신공영(주)\n",
      "35  세종    세종　더휴　예미지　Ｌ２　（국민）  한신공영(주)\n",
      "36  세종    세종　더휴　예미지　Ｌ１　（민영）  한신공영(주)\n",
      "37  세종    세종　더휴　예미지　Ｌ１　（국민）  한신공영(주)\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(bad_companys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   지역                  주택명      시공사\n",
      "0  경기    남양주별내Ａ１－２　행복주택　추가  대보건설(주)\n",
      "1  충남  논산내동２－１　１０년　공공임대　예비  한신공영(주)\n",
      "2  세종    세종　더휴　예미지　Ｌ２　（민영）  한신공영(주)\n",
      "3  세종    세종　더휴　예미지　Ｌ２　（국민）  한신공영(주)\n",
      "4  세종    세종　더휴　예미지　Ｌ１　（민영）  한신공영(주)\n",
      "5  세종    세종　더휴　예미지　Ｌ１　（국민）  한신공영(주)\n"
     ]
    }
   ],
   "source": [
    "# 새로운 인덱스 설정\n",
    "bad_companys.reset_index(drop=True, inplace=True)\n",
    "print(bad_companys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 지역, 주택명, 시공사 수집하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(driver):\n",
    "    # 데이터를 담을 리스트 초기화\n",
    "    data = []\n",
    "\n",
    "    # 다음 페이지 버튼을 클릭하여 더 많은 데이터를 로드하고 파싱합니다.\n",
    "    while True:\n",
    "        # 현재 페이지의 HTML 가져오기\n",
    "        present_url = driver.page_source\n",
    "        \n",
    "        # BeautifulSoup을 사용하여 HTML 파싱\n",
    "        soup = BeautifulSoup(present_url, 'html.parser')\n",
    "        \n",
    "        # tr 요소들을 찾아 반복\n",
    "        for tr in soup.find_all('tr'):\n",
    "            try:\n",
    "                # 각 컬럼의 값을 가져와서 딕셔너리로 저장\n",
    "                td_element = tr.find('td')\n",
    "                b_element = tr.find('b')\n",
    "                word_cut_element = tr.find(class_='word_cut')\n",
    "\n",
    "                # 요소가 존재하는지 확인하고 데이터에 추가\n",
    "                if td_element and b_element and word_cut_element:\n",
    "                    region = td_element.text.strip()\n",
    "                    housing_name = b_element.text.strip()\n",
    "                    construction_company = word_cut_element.text.strip()\n",
    "\n",
    "                    # 딕셔너리에 저장\n",
    "                    row = {'지역': region, '주택명': housing_name, '시공사': construction_company}\n",
    "                    data.append(row)\n",
    "            except AttributeError as e:\n",
    "                print(\"Error:\", e)\n",
    "                continue\n",
    "        \n",
    "        # 현재 페이지 번호 가져오기\n",
    "        current_page_element = soup.find('a', class_='active')\n",
    "        current_page = int(current_page_element.text.strip())\n",
    "\n",
    "        # 다음 페이지로 이동\n",
    "        next_page = current_page + 1\n",
    "        try:\n",
    "            next_page_button = driver.find_element(By.XPATH, f'//a[@href=\"?pageIndex={next_page}\"]')\n",
    "            next_page_button.click()\n",
    "            time.sleep(2)  # 페이지가 로드될 때까지 잠시 대기\n",
    "        except NoSuchElementException:\n",
    "            break\n",
    "    \n",
    "    # 데이터 프레임 생성\n",
    "    df_APT_list = pd.DataFrame(data)\n",
    "    \n",
    "    return df_APT_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 철근 누락 건설사 여부 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_relationship(df, bad_company):\n",
    "    # \"시공사\" 컬럼의 요소와 텍스트가 같거나 서로 포함되는 문자열 관계인 경우 찾기\n",
    "    bad_company_elements = []\n",
    "    for index, row in df.iterrows():\n",
    "        for company in bad_company:\n",
    "            # row['시공사'] 또는 company가 None이 아니고, 서로 포함되는 문자열 관계인 경우\n",
    "            if row['시공사'] and company and (company in row['시공사'] or row['시공사'] in company):\n",
    "                bad_company_elements.append(row)\n",
    "                break\n",
    "\n",
    "    # None을 제외한 bad_company_elements를 데이터프레임으로 변환\n",
    "    bad_companies = pd.DataFrame([elem for elem in bad_company_elements if elem is not None])\n",
    "\n",
    "    return bad_companies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5개년 조사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eda_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
